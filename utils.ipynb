{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\" Mount Drive \"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEjcoY40txMe","outputId":"1e595a2f-35f8-4189-a678-f8d6198d08ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras import layers\n"],"metadata":{"id":"NUtFLmP_Eq64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gV-2Ik_kfxmV"},"source":["### Stanford 40"]},{"cell_type":"code","metadata":{"id":"HhJtnW9eCTHd"},"source":["def onceSF():\n","  #Import dataset\n","  !wget http://vision.stanford.edu/Datasets/Stanford40_JPEGImages.zip\n","  !wget http://vision.stanford.edu/Datasets/Stanford40_ImageSplits.zip\n","\n","  #Unzip it\n","  !unzip Stanford40_JPEGImages.zip -d Stanford40/\n","  !unzip Stanford40_ImageSplits.zip -d Stanford40/\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XECyi77uk9Tf"},"source":["### TV Human Interaction (TV-HI)"]},{"cell_type":"code","source":["def onceTVHI():\n","\n","  #Download data\n","  !wget http://www.robots.ox.ac.uk/~alonso/data/tv_human_interactions_videos.tar.gz\n","  !wget http://www.robots.ox.ac.uk/~alonso/data/readme.txt\n","\n","  #Untar compressed files and move the readme.txt into TV-HI folder\n","  !mkdir TVHI_data\n","  !tar -xvf  'tv_human_interactions_videos.tar.gz' -C TVHI_data\n","  !mv readme.txt 'TV-HI/readme.txt'"],"metadata":{"id":"9L_i9Lgq_BRK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main body utils###"],"metadata":{"id":"tyPoANBbBqNr"}},{"cell_type":"code","source":["\"\"\" Function for sorting the Stanford40 data in a way that can be accessed by Keras data loading function \"\"\"\n","\n","def dataExtractionSF(needDirectories):\n","    onceSF()\n","\n","    with open('Stanford40/ImageSplits/train.txt', 'r') as f:\n","        train_files = list(map(str.strip, f.readlines()))\n","        train_labels = ['_'.join(name.split('_')[:-1]) for name in train_files]\n","    \n","    \n","    with open('Stanford40/ImageSplits/test.txt', 'r') as f:\n","        test_files = list(map(str.strip, f.readlines()))\n","        test_labels = ['_'.join(name.split('_')[:-1]) for name in test_files]\n","\n","        \n","    action_categories = sorted(list(set(['_'.join(name.split('_')[:-1]) for name in train_files])))  \n","\n","    #Split training data here \n","    train_files, validation_files, train_labels, validation_labels = train_test_split(train_files, train_labels, test_size=0.1, random_state=0, stratify=train_labels)\n","\n","    if needDirectories:\n","\n","        print(\"Beginning sorting images...\")\n","            # Specify names of directories for train and test data\n","        dirs_needed = [\"SF_train\", \"SF_test\", \"SF_validation\"]\n","        files_n_labels = [[train_files, train_labels], [test_files, test_labels],[validation_files, validation_labels]]\n","\n","        for s in range(len(dirs_needed)):\n","\n","            os.mkdir(dirs_needed[s]) # make directory each for training and test set\n","\n","            for label in action_categories:\n","                os.mkdir(f\"{dirs_needed[s]}/{label}\") # in each directory make directories for all categories\n","\n","            counter = 0\n","            #Loop through all images and place them in the correct folder\n","            for file in range(len(files_n_labels[s][0])):\n","                label = files_n_labels[s][1][file]\n","                image = cv2.imread(f\"Stanford40/JPEGImages/{files_n_labels[s][0][file]}\")\n","                image_name = f\"{files_n_labels[s][1][file]}_{counter}.jpg\"\n","                print(image_name, label)\n","                path = f'./{dirs_needed[s]}/{label}'\n","                counter += 1\n","                cv2.imwrite(os.path.join(path,image_name), image) #Write image to directory \n","\n","        print(\"Done sorting images!\")\n","\n","    return train_labels, test_labels, validation_labels, action_categories\n","\n","\n","\"\"\" Load the Standford40 dataset \"\"\"\n","\n","def loadSF40(img_size=(224,224), needDirectories=False):\n","\n","    train_labels, test_labels, validation_labels, class_names = dataExtractionSF(needDirectories)\n"," \n","    train_ds = keras.utils.image_dataset_from_directory(\n","    directory='SF_train/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size,\n","    shuffle=True\n","    )\n","\n","    val_ds = keras.utils.image_dataset_from_directory(\n","    directory='SF_validation/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size,\n","    shuffle=True\n","    )\n","\n","    test_ds = keras.utils.image_dataset_from_directory(\n","    directory='SF_test/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size\n","    )\n","    \n","    return train_ds, test_ds, val_ds, train_labels, test_labels, validation_labels, class_names\n","\n"],"metadata":{"id":"bPpK5_ygZ8Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\"\"\" Do dataExtraction on TVHI dataset, get the middle frame and sort into directories for easier data loading \"\"\"\n","\n","def dataExtractionTVHI(needDirectories):\n","    onceTVHI()\n","    \n","    set_1_indices = [[2,14,15,16,18,19,20,21,24,25,26,27,28,32,40,41,42,43,44,45,46,47,48,49,50],\n","                    [1,6,7,8,9,10,11,12,13,23,24,25,27,28,29,30,31,32,33,34,35,44,45,47,48],\n","                    [2,3,4,11,12,15,16,17,18,20,21,27,29,30,31,32,33,34,35,36,42,44,46,49,50],\n","                    [1,7,8,9,10,11,12,13,14,16,17,18,22,23,24,26,29,31,35,36,38,39,40,41,42]]\n","    set_2_indices = [[1,3,4,5,6,7,8,9,10,11,12,13,17,22,23,29,30,31,33,34,35,36,37,38,39],\n","                    [2,3,4,5,14,15,16,17,18,19,20,21,22,26,36,37,38,39,40,41,42,43,46,49,50],\n","                    [1,5,6,7,8,9,10,13,14,19,22,23,24,25,26,28,37,38,39,40,41,43,45,47,48],\n","                    [2,3,4,5,6,15,19,20,21,25,27,28,30,32,33,34,37,43,44,45,46,47,48,49,50]]\n","    classes = ['handShake', 'highFive', 'hug', 'kiss']  # we ignore the negative class\n","\n","    # test set\n","    test_files = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_1_indices[c]]\n","    test_labels = [f'{classes[c]}' for c in range(len(classes)) for i in set_1_indices[c]]\n","   \n","    # training set\n","    train_files = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_2_indices[c]]\n","    train_labels = [f'{classes[c]}' for c in range(len(classes)) for i in set_2_indices[c]]\n","     \n","    #Split training data here \n","    train_files, validation_files, train_labels, validation_labels = train_test_split(train_files, train_labels, test_size=0.15, random_state=0, stratify=train_labels)\n","\n","\n","    if needDirectories:\n","        \n","        print(\"Beginning sorting images...\")\n","            # Specify names of directories for train, validation and test data\n","        dirs_needed = [\"TVHI_train\", \"TVHI_test\", \"TVHI_validation\"]\n","        files_n_labels = [[train_files, train_labels], [test_files, test_labels],[validation_files, validation_labels]]\n","\n","        for s in range(len(dirs_needed)):\n","\n","            os.mkdir(dirs_needed[s]) # make directory each for training, validation and test sets\n","\n","            for label in classes:\n","                os.mkdir(f\"{dirs_needed[s]}/{label}\") # in each directory make directories for all categories\n","\n","            counter = 0\n","            #Loop through all videos, take middle frame and place them in the correct folder\n","            for video in range(len(files_n_labels[s][0])):\n","                label = files_n_labels[s][1][video]\n","                vidcap = cv2.VideoCapture(f'TVHI_data/tv_human_interactions_videos/{files_n_labels[s][0][video]}')\n","                middle_frame = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)/2)\n","                vidcap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame) #Get the middle frame of the video\n","                success, frame = vidcap.read()\n","                image_name = f\"{files_n_labels[s][1][video]}_{counter}.jpg\"\n","                print(image_name, label)\n","                path = f'./{dirs_needed[s]}/{label}'\n","                counter += 1\n","                cv2.imwrite(os.path.join(path,image_name), frame) #Write image to directory \n","\n","        print(\"Done sorting images!\")\n","    \n","    \n","    return train_labels, test_labels, validation_labels, classes\n","\n","def loadTVHI(img_size=(224,224), needDirectories=False):\n","\n","    train_labels, test_labels, validation_labels, class_names = dataExtractionTVHI(needDirectories)\n"," \n","    train_ds = keras.utils.image_dataset_from_directory(\n","    directory='TVHI_train/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size,\n","    shuffle=True\n","    )\n","\n","    val_ds = keras.utils.image_dataset_from_directory(\n","    directory='TVHI_validation/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size,\n","    shuffle=True\n","    )\n","\n","    test_ds = keras.utils.image_dataset_from_directory(\n","    directory='TVHI_test/',\n","    labels='inferred',\n","    label_mode='int',\n","    batch_size=32,\n","    image_size=img_size\n","    )\n","    \n","    return train_ds, test_ds, val_ds, train_labels, test_labels, validation_labels, class_names\n"],"metadata":{"id":"cumo8sDxtLV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" the Optical Flow input to the CNN \"\"\"\n","\n","def opticalFlowDataExtraction(IMG_SIZE=(224,224)):\n","    onceTVHI()\n","    \n","    #Take relevant data and create test and training set (set 1 = test set,set 2 = training set)\n","    set_1_indices = [[2,14,15,16,18,19,20,21,24,25,26,27,28,32,40,41,42,43,44,45,46,47,48,49,50],\n","                 [1,6,7,8,9,10,11,12,13,23,24,25,27,28,29,30,31,32,33,34,35,44,45,47,48],\n","                 [2,3,4,11,12,15,16,17,18,20,21,27,29,30,31,32,33,34,35,36,42,44,46,49,50],\n","                 [1,7,8,9,10,11,12,13,14,16,17,18,22,23,24,26,29,31,35,36,38,39,40,41,42]]\n","    set_2_indices = [[1,3,4,5,6,7,8,9,10,11,12,13,17,22,23,29,30,31,33,34,35,36,37,38,39],\n","                    [2,3,4,5,14,15,16,17,18,19,20,21,22,26,36,37,38,39,40,41,42,43,46,49,50],\n","                    [1,5,6,7,8,9,10,13,14,19,22,23,24,25,26,28,37,38,39,40,41,43,45,47,48],\n","                    [2,3,4,5,6,15,19,20,21,25,27,28,30,32,33,34,37,43,44,45,46,47,48,49,50]]\n","    classes = ['handShake', 'highFive', 'hug', 'kiss']  # we ignore the negative class\n"," \n","    # test set\n","    test_files = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_1_indices[c]]\n","    test_labels = [f'{classes[c]}' for c in range(len(classes)) for i in set_1_indices[c]]\n","   \n","    # training set\n","    train_files = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_2_indices[c]]\n","    train_labels = [f'{classes[c]}' for c in range(len(classes)) for i in set_2_indices[c]]\n","     \n","    #Split training data here \n","    train_files, validation_files, train_labels, validation_labels = train_test_split(train_files, train_labels, test_size=0.15, random_state=0, stratify=train_labels)\n","\n","    \n","    print(\"Beginning sorting images...\")\n","        # Specify names of directories for train, validation and test data\n","    dirs_needed = [\"OF_train\", \"OF_test\", \"OF_validation\"]\n","    files_n_labels = [[train_files, train_labels], [test_files, test_labels],[validation_files, validation_labels]]\n","\n","    for s in range(len(dirs_needed)):\n","\n","        os.mkdir(dirs_needed[s]) # make directory each for training, validation and test sets\n","\n","        for label in classes:\n","            os.mkdir(f\"{dirs_needed[s]}/{label}\") # in each directory make directories for all categories\n","\n","        counter = 0\n","        #Loop through all videos, take middle frame and place them in the correct folder\n","        for video in range(len(files_n_labels[s][0])):\n","            video_name = f\"{files_n_labels[s][0][video]}_{counter}\"\n","            os.mkdir(f\"{dirs_needed[s]}/{label}/{video_name}\")\n","            label = files_n_labels[s][1][video]\n","            vidcap = cv2.VideoCapture(f'TVHI_data/tv_human_interactions_videos/{files_n_labels[s][0][video]}')\n","            starting_frame = int((vidcap.get(cv2.CAP_PROP_FRAME_COUNT)/2)-8)\n","            vidcap.set(cv2.CAP_PROP_POS_FRAMES, starting_frame) #Get the middle frame of the video\n","            success, old_frame = vidcap.read()\n","            \n","            #preprocess image\n","            hsv = np.zeros_like(old_frame) \n","            hsv[...,1] = 255                                                # Set HSV's Value-channel to constant\n","            old_frame = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)         # Convert to grayscale to fit algorithm (Farneback)\n","          \n","\n","            counter2 = 0\n","            for i in range(16): #Loop over 16 frames, middle frame will be middle of stack\n","\n","                success, new_frame = vidcap.read()\n","                if not success:\n","                    break\n","                \n","                #Do preprocessing of new frame \n","                new_frame  = cv2.cvtColor(new_frame,cv2.COLOR_BGR2GRAY)\n","                new_frame  = cv2.resize(new_frame, IMG_SIZE)\n","\n","                flow = cv2.calcOpticalFlowFarneback(old_frame,new_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)   # calculate the optical flow for each pixel in the frame with Farneback\n","                \n","                mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])       # find magnitude and direction and encode it in an image\n","                hsv[..., 0] = ang*180/np.pi/2\n","                hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n","                bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","                of_frame  = cv2.resize(bgr, IMG_SIZE)                   # Resize image to fit the other data\n","                \n","                frame_name = f\"{video_name}_{counter2}.jpg\"\n","                path = f'./{dirs_needed[s]}/{label}/{video_name}'\n","                cv2.imwrite(os.path.join(path,frame_name), of_frame) #Write image to directory\n","                counter2 += 1 \n","            \n","            print(f\"{video_name} , {label}\")\n","            counter += 1 \n","\n","    print(\"Done sorting images!\")"],"metadata":{"id":"kmf1TaYjtJGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#opticalFlowDataExtraction()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nNhSdAnr3L67","outputId":"34376b06-d2f9-4328-df02-905af0efe251"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-14 20:57:28--  http://www.robots.ox.ac.uk/~alonso/data/tv_human_interactions_videos.tar.gz\n","Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://www.robots.ox.ac.uk/~alonso/data/tv_human_interactions_videos.tar.gz [following]\n","--2022-04-14 20:57:29--  https://www.robots.ox.ac.uk/~alonso/data/tv_human_interactions_videos.tar.gz\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 163535078 (156M) [application/x-gzip]\n","Saving to: ‘tv_human_interactions_videos.tar.gz.1’\n","\n","tv_human_interactio 100%[===================>] 155.96M  28.1MB/s    in 6.2s    \n","\n","2022-04-14 20:57:35 (25.0 MB/s) - ‘tv_human_interactions_videos.tar.gz.1’ saved [163535078/163535078]\n","\n","--2022-04-14 20:57:35--  http://www.robots.ox.ac.uk/~alonso/data/readme.txt\n","Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://www.robots.ox.ac.uk/~alonso/data/readme.txt [following]\n","--2022-04-14 20:57:36--  https://www.robots.ox.ac.uk/~alonso/data/readme.txt\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2514 (2.5K) [text/plain]\n","Saving to: ‘readme.txt.1’\n","\n","readme.txt.1        100%[===================>]   2.46K  --.-KB/s    in 0s      \n","\n","2022-04-14 20:57:36 (157 MB/s) - ‘readme.txt.1’ saved [2514/2514]\n","\n","mkdir: cannot create directory ‘TVHI_data’: File exists\n","tv_human_interactions_videos/\n","tv_human_interactions_videos/negative_0001.avi\n","tv_human_interactions_videos/negative_0002.avi\n","tv_human_interactions_videos/negative_0003.avi\n","tv_human_interactions_videos/negative_0004.avi\n","tv_human_interactions_videos/negative_0005.avi\n","tv_human_interactions_videos/negative_0006.avi\n","tv_human_interactions_videos/negative_0007.avi\n","tv_human_interactions_videos/negative_0008.avi\n","tv_human_interactions_videos/negative_0009.avi\n","tv_human_interactions_videos/negative_0010.avi\n","tv_human_interactions_videos/negative_0011.avi\n","tv_human_interactions_videos/negative_0012.avi\n","tv_human_interactions_videos/negative_0013.avi\n","tv_human_interactions_videos/negative_0014.avi\n","tv_human_interactions_videos/negative_0015.avi\n","tv_human_interactions_videos/negative_0016.avi\n","tv_human_interactions_videos/negative_0017.avi\n","tv_human_interactions_videos/negative_0018.avi\n","tv_human_interactions_videos/negative_0019.avi\n","tv_human_interactions_videos/negative_0020.avi\n","tv_human_interactions_videos/negative_0021.avi\n","tv_human_interactions_videos/negative_0022.avi\n","tv_human_interactions_videos/negative_0023.avi\n","tv_human_interactions_videos/negative_0024.avi\n","tv_human_interactions_videos/negative_0025.avi\n","tv_human_interactions_videos/negative_0026.avi\n","tv_human_interactions_videos/negative_0027.avi\n","tv_human_interactions_videos/negative_0028.avi\n","tv_human_interactions_videos/negative_0029.avi\n","tv_human_interactions_videos/negative_0030.avi\n","tv_human_interactions_videos/negative_0031.avi\n","tv_human_interactions_videos/negative_0032.avi\n","tv_human_interactions_videos/negative_0033.avi\n","tv_human_interactions_videos/negative_0034.avi\n","tv_human_interactions_videos/negative_0035.avi\n","tv_human_interactions_videos/negative_0036.avi\n","tv_human_interactions_videos/negative_0037.avi\n","tv_human_interactions_videos/negative_0038.avi\n","tv_human_interactions_videos/negative_0039.avi\n","tv_human_interactions_videos/negative_0040.avi\n","tv_human_interactions_videos/negative_0041.avi\n","tv_human_interactions_videos/negative_0042.avi\n","tv_human_interactions_videos/negative_0043.avi\n","tv_human_interactions_videos/negative_0044.avi\n","tv_human_interactions_videos/negative_0045.avi\n","tv_human_interactions_videos/negative_0046.avi\n","tv_human_interactions_videos/negative_0047.avi\n","tv_human_interactions_videos/negative_0048.avi\n","tv_human_interactions_videos/negative_0049.avi\n","tv_human_interactions_videos/negative_0050.avi\n","tv_human_interactions_videos/negative_0051.avi\n","tv_human_interactions_videos/negative_0052.avi\n","tv_human_interactions_videos/negative_0053.avi\n","tv_human_interactions_videos/negative_0054.avi\n","tv_human_interactions_videos/negative_0055.avi\n","tv_human_interactions_videos/negative_0056.avi\n","tv_human_interactions_videos/negative_0057.avi\n","tv_human_interactions_videos/negative_0058.avi\n","tv_human_interactions_videos/negative_0059.avi\n","tv_human_interactions_videos/negative_0060.avi\n","tv_human_interactions_videos/negative_0061.avi\n","tv_human_interactions_videos/negative_0062.avi\n","tv_human_interactions_videos/negative_0063.avi\n","tv_human_interactions_videos/negative_0064.avi\n","tv_human_interactions_videos/negative_0065.avi\n","tv_human_interactions_videos/negative_0066.avi\n","tv_human_interactions_videos/negative_0067.avi\n","tv_human_interactions_videos/negative_0068.avi\n","tv_human_interactions_videos/negative_0069.avi\n","tv_human_interactions_videos/negative_0070.avi\n","tv_human_interactions_videos/negative_0071.avi\n","tv_human_interactions_videos/negative_0072.avi\n","tv_human_interactions_videos/negative_0073.avi\n","tv_human_interactions_videos/negative_0074.avi\n","tv_human_interactions_videos/negative_0075.avi\n","tv_human_interactions_videos/negative_0076.avi\n","tv_human_interactions_videos/negative_0077.avi\n","tv_human_interactions_videos/negative_0078.avi\n","tv_human_interactions_videos/negative_0079.avi\n","tv_human_interactions_videos/negative_0080.avi\n","tv_human_interactions_videos/negative_0081.avi\n","tv_human_interactions_videos/negative_0082.avi\n","tv_human_interactions_videos/negative_0083.avi\n","tv_human_interactions_videos/negative_0084.avi\n","tv_human_interactions_videos/negative_0085.avi\n","tv_human_interactions_videos/negative_0086.avi\n","tv_human_interactions_videos/negative_0087.avi\n","tv_human_interactions_videos/negative_0088.avi\n","tv_human_interactions_videos/negative_0089.avi\n","tv_human_interactions_videos/negative_0090.avi\n","tv_human_interactions_videos/negative_0091.avi\n","tv_human_interactions_videos/negative_0092.avi\n","tv_human_interactions_videos/negative_0093.avi\n","tv_human_interactions_videos/negative_0094.avi\n","tv_human_interactions_videos/negative_0095.avi\n","tv_human_interactions_videos/negative_0096.avi\n","tv_human_interactions_videos/negative_0097.avi\n","tv_human_interactions_videos/negative_0098.avi\n","tv_human_interactions_videos/negative_0099.avi\n","tv_human_interactions_videos/negative_0100.avi\n","tv_human_interactions_videos/handShake_0001.avi\n","tv_human_interactions_videos/handShake_0002.avi\n","tv_human_interactions_videos/handShake_0003.avi\n","tv_human_interactions_videos/handShake_0004.avi\n","tv_human_interactions_videos/handShake_0005.avi\n","tv_human_interactions_videos/handShake_0006.avi\n","tv_human_interactions_videos/handShake_0007.avi\n","tv_human_interactions_videos/handShake_0008.avi\n","tv_human_interactions_videos/handShake_0009.avi\n","tv_human_interactions_videos/handShake_0010.avi\n","tv_human_interactions_videos/handShake_0011.avi\n","tv_human_interactions_videos/handShake_0012.avi\n","tv_human_interactions_videos/handShake_0013.avi\n","tv_human_interactions_videos/handShake_0014.avi\n","tv_human_interactions_videos/handShake_0015.avi\n","tv_human_interactions_videos/handShake_0016.avi\n","tv_human_interactions_videos/handShake_0017.avi\n","tv_human_interactions_videos/handShake_0018.avi\n","tv_human_interactions_videos/handShake_0019.avi\n","tv_human_interactions_videos/handShake_0020.avi\n","tv_human_interactions_videos/handShake_0021.avi\n","tv_human_interactions_videos/handShake_0022.avi\n","tv_human_interactions_videos/handShake_0023.avi\n","tv_human_interactions_videos/handShake_0024.avi\n","tv_human_interactions_videos/handShake_0025.avi\n","tv_human_interactions_videos/handShake_0026.avi\n","tv_human_interactions_videos/handShake_0027.avi\n","tv_human_interactions_videos/handShake_0028.avi\n","tv_human_interactions_videos/handShake_0029.avi\n","tv_human_interactions_videos/handShake_0030.avi\n","tv_human_interactions_videos/handShake_0031.avi\n","tv_human_interactions_videos/handShake_0032.avi\n","tv_human_interactions_videos/handShake_0033.avi\n","tv_human_interactions_videos/handShake_0034.avi\n","tv_human_interactions_videos/handShake_0035.avi\n","tv_human_interactions_videos/handShake_0036.avi\n","tv_human_interactions_videos/handShake_0037.avi\n","tv_human_interactions_videos/handShake_0038.avi\n","tv_human_interactions_videos/handShake_0039.avi\n","tv_human_interactions_videos/handShake_0040.avi\n","tv_human_interactions_videos/handShake_0041.avi\n","tv_human_interactions_videos/handShake_0042.avi\n","tv_human_interactions_videos/handShake_0043.avi\n","tv_human_interactions_videos/handShake_0044.avi\n","tv_human_interactions_videos/handShake_0045.avi\n","tv_human_interactions_videos/handShake_0046.avi\n","tv_human_interactions_videos/handShake_0047.avi\n","tv_human_interactions_videos/handShake_0048.avi\n","tv_human_interactions_videos/handShake_0049.avi\n","tv_human_interactions_videos/handShake_0050.avi\n","tv_human_interactions_videos/highFive_0001.avi\n","tv_human_interactions_videos/highFive_0002.avi\n","tv_human_interactions_videos/highFive_0003.avi\n","tv_human_interactions_videos/highFive_0004.avi\n","tv_human_interactions_videos/highFive_0005.avi\n","tv_human_interactions_videos/highFive_0006.avi\n","tv_human_interactions_videos/highFive_0007.avi\n","tv_human_interactions_videos/highFive_0008.avi\n","tv_human_interactions_videos/highFive_0009.avi\n","tv_human_interactions_videos/highFive_0010.avi\n","tv_human_interactions_videos/highFive_0011.avi\n","tv_human_interactions_videos/highFive_0012.avi\n","tv_human_interactions_videos/highFive_0013.avi\n","tv_human_interactions_videos/highFive_0014.avi\n","tv_human_interactions_videos/highFive_0015.avi\n","tv_human_interactions_videos/highFive_0016.avi\n","tv_human_interactions_videos/highFive_0017.avi\n","tv_human_interactions_videos/highFive_0018.avi\n","tv_human_interactions_videos/highFive_0019.avi\n","tv_human_interactions_videos/highFive_0020.avi\n","tv_human_interactions_videos/highFive_0021.avi\n","tv_human_interactions_videos/highFive_0022.avi\n","tv_human_interactions_videos/highFive_0023.avi\n","tv_human_interactions_videos/highFive_0024.avi\n","tv_human_interactions_videos/highFive_0025.avi\n","tv_human_interactions_videos/highFive_0026.avi\n","tv_human_interactions_videos/highFive_0027.avi\n","tv_human_interactions_videos/highFive_0028.avi\n","tv_human_interactions_videos/highFive_0029.avi\n","tv_human_interactions_videos/highFive_0030.avi\n","tv_human_interactions_videos/highFive_0031.avi\n","tv_human_interactions_videos/highFive_0032.avi\n","tv_human_interactions_videos/highFive_0033.avi\n","tv_human_interactions_videos/highFive_0034.avi\n","tv_human_interactions_videos/highFive_0035.avi\n","tv_human_interactions_videos/highFive_0036.avi\n","tv_human_interactions_videos/highFive_0037.avi\n","tv_human_interactions_videos/highFive_0038.avi\n","tv_human_interactions_videos/highFive_0039.avi\n","tv_human_interactions_videos/highFive_0040.avi\n","tv_human_interactions_videos/highFive_0041.avi\n","tv_human_interactions_videos/highFive_0042.avi\n","tv_human_interactions_videos/highFive_0043.avi\n","tv_human_interactions_videos/highFive_0044.avi\n","tv_human_interactions_videos/highFive_0045.avi\n","tv_human_interactions_videos/highFive_0046.avi\n","tv_human_interactions_videos/highFive_0047.avi\n","tv_human_interactions_videos/highFive_0048.avi\n","tv_human_interactions_videos/highFive_0049.avi\n","tv_human_interactions_videos/highFive_0050.avi\n","tv_human_interactions_videos/hug_0001.avi\n","tv_human_interactions_videos/hug_0002.avi\n","tv_human_interactions_videos/hug_0003.avi\n","tv_human_interactions_videos/hug_0004.avi\n","tv_human_interactions_videos/hug_0005.avi\n","tv_human_interactions_videos/hug_0006.avi\n","tv_human_interactions_videos/hug_0007.avi\n","tv_human_interactions_videos/hug_0008.avi\n","tv_human_interactions_videos/hug_0009.avi\n","tv_human_interactions_videos/hug_0010.avi\n","tv_human_interactions_videos/hug_0011.avi\n","tv_human_interactions_videos/hug_0012.avi\n","tv_human_interactions_videos/hug_0013.avi\n","tv_human_interactions_videos/hug_0014.avi\n","tv_human_interactions_videos/hug_0015.avi\n","tv_human_interactions_videos/hug_0016.avi\n","tv_human_interactions_videos/hug_0017.avi\n","tv_human_interactions_videos/hug_0018.avi\n","tv_human_interactions_videos/hug_0019.avi\n","tv_human_interactions_videos/hug_0020.avi\n","tv_human_interactions_videos/hug_0021.avi\n","tv_human_interactions_videos/hug_0022.avi\n","tv_human_interactions_videos/hug_0023.avi\n","tv_human_interactions_videos/hug_0024.avi\n","tv_human_interactions_videos/hug_0025.avi\n","tv_human_interactions_videos/hug_0026.avi\n","tv_human_interactions_videos/hug_0027.avi\n","tv_human_interactions_videos/hug_0028.avi\n","tv_human_interactions_videos/hug_0029.avi\n","tv_human_interactions_videos/hug_0030.avi\n","tv_human_interactions_videos/hug_0031.avi\n","tv_human_interactions_videos/hug_0032.avi\n","tv_human_interactions_videos/hug_0033.avi\n","tv_human_interactions_videos/hug_0034.avi\n","tv_human_interactions_videos/hug_0035.avi\n","tv_human_interactions_videos/hug_0036.avi\n","tv_human_interactions_videos/hug_0037.avi\n","tv_human_interactions_videos/hug_0038.avi\n","tv_human_interactions_videos/hug_0039.avi\n","tv_human_interactions_videos/hug_0040.avi\n","tv_human_interactions_videos/hug_0041.avi\n","tv_human_interactions_videos/hug_0042.avi\n","tv_human_interactions_videos/hug_0043.avi\n","tv_human_interactions_videos/hug_0044.avi\n","tv_human_interactions_videos/hug_0045.avi\n","tv_human_interactions_videos/hug_0046.avi\n","tv_human_interactions_videos/hug_0047.avi\n","tv_human_interactions_videos/hug_0048.avi\n","tv_human_interactions_videos/hug_0049.avi\n","tv_human_interactions_videos/hug_0050.avi\n","tv_human_interactions_videos/kiss_0001.avi\n","tv_human_interactions_videos/kiss_0002.avi\n","tv_human_interactions_videos/kiss_0003.avi\n","tv_human_interactions_videos/kiss_0004.avi\n","tv_human_interactions_videos/kiss_0005.avi\n","tv_human_interactions_videos/kiss_0006.avi\n","tv_human_interactions_videos/kiss_0007.avi\n","tv_human_interactions_videos/kiss_0008.avi\n","tv_human_interactions_videos/kiss_0009.avi\n","tv_human_interactions_videos/kiss_0010.avi\n","tv_human_interactions_videos/kiss_0011.avi\n","tv_human_interactions_videos/kiss_0012.avi\n","tv_human_interactions_videos/kiss_0013.avi\n","tv_human_interactions_videos/kiss_0014.avi\n","tv_human_interactions_videos/kiss_0015.avi\n","tv_human_interactions_videos/kiss_0016.avi\n","tv_human_interactions_videos/kiss_0017.avi\n","tv_human_interactions_videos/kiss_0018.avi\n","tv_human_interactions_videos/kiss_0019.avi\n","tv_human_interactions_videos/kiss_0020.avi\n","tv_human_interactions_videos/kiss_0021.avi\n","tv_human_interactions_videos/kiss_0022.avi\n","tv_human_interactions_videos/kiss_0023.avi\n","tv_human_interactions_videos/kiss_0024.avi\n","tv_human_interactions_videos/kiss_0025.avi\n","tv_human_interactions_videos/kiss_0026.avi\n","tv_human_interactions_videos/kiss_0027.avi\n","tv_human_interactions_videos/kiss_0028.avi\n","tv_human_interactions_videos/kiss_0029.avi\n","tv_human_interactions_videos/kiss_0030.avi\n","tv_human_interactions_videos/kiss_0031.avi\n","tv_human_interactions_videos/kiss_0032.avi\n","tv_human_interactions_videos/kiss_0033.avi\n","tv_human_interactions_videos/kiss_0034.avi\n","tv_human_interactions_videos/kiss_0035.avi\n","tv_human_interactions_videos/kiss_0036.avi\n","tv_human_interactions_videos/kiss_0037.avi\n","tv_human_interactions_videos/kiss_0038.avi\n","tv_human_interactions_videos/kiss_0039.avi\n","tv_human_interactions_videos/kiss_0040.avi\n","tv_human_interactions_videos/kiss_0041.avi\n","tv_human_interactions_videos/kiss_0042.avi\n","tv_human_interactions_videos/kiss_0043.avi\n","tv_human_interactions_videos/kiss_0044.avi\n","tv_human_interactions_videos/kiss_0045.avi\n","tv_human_interactions_videos/kiss_0046.avi\n","tv_human_interactions_videos/kiss_0047.avi\n","tv_human_interactions_videos/kiss_0048.avi\n","tv_human_interactions_videos/kiss_0049.avi\n","tv_human_interactions_videos/kiss_0050.avi\n","mv: cannot move 'readme.txt' to 'TV-HI/readme.txt': No such file or directory\n","Beginning sorting images...\n"]},{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-1456a0de4282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopticalFlowDataExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-dddc7b72383c>\u001b[0m in \u001b[0;36mopticalFlowDataExtraction\u001b[0;34m(IMG_SIZE)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_needed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make directory each for training, validation and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'OF_train'"]}]},{"cell_type":"code","source":["\n","\"\"\"   Data augmentation and Normalisation \"\"\"\n","def dataAugmentation():\n","\n","    img_augmentation = Sequential(\n","    [\n","        #layers.Rescaling(scale=1./255),\n","        layers.RandomRotation(factor=0.15),\n","        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n","        layers.RandomFlip(mode=\"horizontal\"),\n","        layers.RandomContrast(factor=0.1),\n","        layers.RandomZoom(0.1)\n","    ],\n","    name=\"img_augmentation\",\n","    )\n","\n","    return img_augmentation\n","\n","\n","\"\"\" Function for plotting accuracy\"\"\"\n","\n","def plotAccuracy(title, train_acc, val_acc):\n","    plt.title(title)\n","    plt.plot(train_acc)\n","    plt.plot(val_acc)\n","    plt.ylabel(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend(['train', 'val'], loc = 'upper left')\n","    plt.ylim([0, 1])\n","    plt.show()\n","\n","\"\"\" Function for plotting loss\"\"\"\n","\n","def plotLoss(title, train_loss, val_loss):\n","    plt.title(title)\n","    plt.plot(train_loss)\n","    plt.plot(val_loss)\n","    plt.ylabel(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend(['train', 'val'], loc = 'lower left')\n","    plt.ylim([0, 5])\n","    plt.show()\n"],"metadata":{"id":"J8KpxkDQtEiO"},"execution_count":null,"outputs":[]}]}