{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pcsu2gb3IpJw"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6560/4212172852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install kora -q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkora\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlink_nbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kora\\drive.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munquote\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "!pip install kora -q\n",
    "from kora import drive\n",
    "drive.link_nbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPagwXQbJIMw",
    "outputId": "c75fe1cf-9312-4585-90eb-5161962f33e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /nbs/utils.ipynb\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HBRlCZcI9eA0"
   },
   "outputs": [],
   "source": [
    "SF_notloaded = True   #set to True after first run once you have your files in the Files folder of Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p-WbTTXj9Y2-"
   },
   "outputs": [],
   "source": [
    "if not SF_notloaded:\n",
    "  utils.onceSF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WNGiwI1zs0tX"
   },
   "outputs": [],
   "source": [
    "#!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "S_f01t8FEah9",
    "outputId": "74570f74-4295-436c-dda9-bb1510db8d2f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a61f0d137170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'efficientnet'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import efficientnet.keras as efn\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GmpYNeySWaE"
   },
   "outputs": [],
   "source": [
    "\"\"\" Load dataset \"\"\"\n",
    "#Load the dataset which has already been preprocessed\n",
    "SF_training_set, train_labels, SF_test_set, test_labels, class_names = utils.loadSF40(img_size =  IMG_SIZE)\n",
    "\n",
    "#Split the trainingset to obtain 10% stratified validation set\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(SF_training_set, train_labels, test_size=0.1, random_state=0, stratify=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3azVE7J5GtU3",
    "outputId": "fab62396-c74d-4f34-cd90-8d66459fdd22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengt of train_files:  4000\n",
      "Action categories (40):\n",
      "['applauding', 'blowing_bubbles', 'brushing_teeth', 'cleaning_the_floor', 'climbing', 'cooking', 'cutting_trees', 'cutting_vegetables', 'drinking', 'feeding_a_horse', 'fishing', 'fixing_a_bike', 'fixing_a_car', 'gardening', 'holding_an_umbrella', 'jumping', 'looking_through_a_microscope', 'looking_through_a_telescope', 'phoning', 'playing_guitar', 'playing_violin', 'pouring_liquid', 'pushing_a_cart', 'reading', 'riding_a_bike', 'riding_a_horse', 'rowing_a_boat', 'running', 'shooting_an_arrow', 'smoking', 'taking_photos', 'texting_message', 'throwing_frisby', 'using_a_computer', 'walking_the_dog', 'washing_dishes', 'watching_TV', 'waving_hands', 'writing_on_a_board', 'writing_on_a_book']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Global variables \"\"\"\n",
    "IMG_SIZE = (224,224)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "NO_TRAIN_IMGS = len(train_labels)\n",
    "NO_VAL_IMGS = len(validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5GaJR8fGwxU"
   },
   "outputs": [],
   "source": [
    "\"\"\"   Data augmentation and Normalisation \"\"\"\n",
    "# data augmentation generator defining the augmentations and data-preprocessing to be made\n",
    "data_generator = ImageDataGenerator(\n",
    "        rescale=1.0/255.0, #normalising pixel values to range 0-1\n",
    "        rotation_range=20, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        brightness_range=[0.5,1.2]  # brightness\n",
    "        )\n",
    "\n",
    "#Create iterators to pass to the model during training\n",
    "train_iterator = data_generator.flow(train_images, train_labels, batch_size=64)\n",
    "validation_iterator =  data_generator.flow(validation_images, validation_labels, batch_size=64)\n",
    "test_iterator = data_generator.flow(SF_test_set, test_labels, batch_size=64)\n",
    "\n",
    "\n",
    "\"\"\" This is how we will fit it with the model \"\"\"\n",
    "# fit model with generator\n",
    "# model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
    "# # evaluate model\n",
    "# _, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/ \n",
    "\n",
    "\"\"\" One-hot encoding \"\"\"\n",
    "\n",
    "def onehot_encoding(image, label):\n",
    "    label = tf.one_hot(label, class_names)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_images = train_images.map(\n",
    "    onehot_encoding, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_images = train_images.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
    "train_images = train_images.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "SF_test_set = SF_test_set.map(onehot_encoding)\n",
    "SF_test_set = SF_test_set.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJpk-LUKv3Bd"
   },
   "outputs": [],
   "source": [
    "\"\"\" Tutorials used to build model\"\"\"\n",
    "#https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
    "#https://towardsdatascience.com/an-in-depth-efficientnet-tutorial-using-tensorflow-how-to-use-efficientnet-on-a-custom-dataset-1cab0997f65c\n",
    "#https://www.kaggle.com/code/arjunrao2000/beginners-guide-efficientnet-with-keras/notebook\n",
    "\n",
    "\"\"\" Cyclical learning rate example\"\"\"\n",
    "#https://pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6jhSDacXRqz"
   },
   "outputs": [],
   "source": [
    "\"\"\" Build & Train Stanford40 Model EfficientNet\"\"\"\n",
    "\n",
    "# Define the input and output layers of the model \n",
    "inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "outputs = efn.EfficientNetB0(include_top=True, weights=None, classes=class_names) #Include top set to true as we are not using pre-trained weights but training from scratch\n",
    "\n",
    "# Initialise the model. Compule and show summary. \n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Fit the model with the data augmentation and normalisation iterators\n",
    "history = model.fit_generator(train_iterator, epochs = EPOCHS, steps_per_epoch = NO_TRAIN_IMGS//BATCH_SIZE, \n",
    "                              validation_data = validation_iterator, validation_steps=NO_VAL_IMGS//BATCH_SIZE, \n",
    "                              verbose=1, use_multiprocessing=True, workers=4)\n",
    "\n",
    "#Save weights as we need these for transfer learning \n",
    "model.save_weights(\"model_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTFfDg7PUSGh"
   },
   "outputs": [],
   "source": [
    "TL_model = \n",
    "\n",
    "\n",
    "TL_model.load_weights(\"model_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
