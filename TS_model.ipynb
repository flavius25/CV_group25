{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TS_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()"
      ],
      "metadata": {
        "id": "le4fICTCR_Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "import ResNet18\n",
        "import OF_CNN"
      ],
      "metadata": {
        "id": "LrJU2gVXR_-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T894ekj3RfcO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import TimeDistributed, Input, MaxPooling3D, LSTM, Dense, Conv3D, Conv2D, BatchNormalization, Flatten, Dropout, Convolution2D, Activation, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras import losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" GLOBAL VARIABLES \"\"\"\n",
        "NUM_CLASSES = 4\n",
        "EPOCHS = 10\n",
        "INSTACK = 16\n",
        "IMG_SIZE = (224, 224)\n",
        "LEN_TRAIN = 85"
      ],
      "metadata": {
        "id": "rR8vx0PFjCki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Data loading \"\"\"\n",
        "\n",
        "train_gen = joinedGen(Train=True)\n",
        "val_gen = joinedGen(Val=True)"
      ],
      "metadata": {
        "id": "vjryUa3LjMIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TVHI_weights = \"/___/____/\"\n",
        "OF_weights = \"___/___/_\""
      ],
      "metadata": {
        "id": "TBMLPkXrT-xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Building Model \"\"\"\n",
        "\n",
        "#Baseline model to keep expanding based on example from: https://keras.io/guides/training_with_built_in_methods/#passing-data-to-multiinput-multioutput-models\n",
        "def build_TS_model():\n",
        "  img_input = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name=\"img_input\")\n",
        "  of_input = keras.Input(shape=(INSTACK,IMG_SIZE[0],IMG_SIZE[1],3), name=\"of_input\")\n",
        "\n",
        "  #Set up basemodels, load weights, remove certain layers, check output sizes. If not the same, use 1D convolutions, fuse together dense layers using the concatenate. \n",
        "  #Freeze baseline models. Set new layers to trainable. Train. Save weights and model. \n",
        "  resnet_base = ResNet18.ResNet18(NUM_CLASSES)\n",
        "  resnet_base.load_weights(TVHI_weights)\n",
        "\n",
        "  of_base = OF_CNN.build_OF_model((INSTACK, IMG_SIZE[0], IMG_SIZE[1], 3), NUM_CLASSES)\n",
        "  of_base.load_weights(OF_weights)\n",
        "\n",
        "  x1 = layers.Conv2D(3, 3)(image_input)\n",
        "  x1 = layers.GlobalMaxPooling2D()(x1)\n",
        "\n",
        "  x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
        "  x2 = layers.GlobalMaxPooling1D()(x2)\n",
        "\n",
        "  x = layers.concatenate([x1, x2])\n",
        "\n",
        "\n",
        "  class_output = layers.Dense(NUM_CLASSES,  activation='softmax', name=\"pred\")(x)\n",
        "\n",
        "  model = keras.Model(\n",
        "      inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
        "  )\n",
        "  model.compile(loss='categorical crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model \n"
      ],
      "metadata": {
        "id": "FIDMd-c5X9QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Plot the model \"\"\"\n",
        "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "VRI7ozzBkrqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Set up callback and perform training \"\"\"\n",
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "ts_history = of_model.fit(train_gen,epochs= EPOCHS, steps_per_epoch = LEN_TRAIN, validation_data=val_gen, validation_steps=15, callbacks= callback, verbose=1)"
      ],
      "metadata": {
        "id": "JRBlVErZlHg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Save model and weights \"\"\"\n",
        "ts_model.save_weights('TS_weights.h5')\n",
        "ts_model.save(\"TS_model\", save_format = 'tf', include_optimizer=True)"
      ],
      "metadata": {
        "id": "pOr_G-W4lSxQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}